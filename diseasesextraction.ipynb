{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Extraction (NER problem) \n",
    "https://datahack.analyticsvidhya.com/contest/innoplexus-online-hiring-hackathon-saving-lives-wi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs:  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "from itertools import repeat\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import spacy\n",
    "import scispacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import gc\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "N_CORES = multiprocessing.cpu_count()\n",
    "print('Number of CPUs: ', N_CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_named_entities(tokens): # Helper Function for score calculation\n",
    "    \"\"\"\n",
    "    Creates a list of Entity named-tuples, storing the entity type and the start and end\n",
    "    offsets of the entity.\n",
    "    :param tokens: a list of labels\n",
    "    :return: a list of Entity named-tuples\n",
    "    \"\"\"\n",
    "    Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n",
    "    named_entities = []\n",
    "    start_offset = None\n",
    "    end_offset = None\n",
    "    ent_type = None\n",
    "\n",
    "    for offset, token_tag in enumerate(tokens):\n",
    "\n",
    "        if token_tag == 'O':\n",
    "            if ent_type is not None and start_offset is not None:\n",
    "                end_offset = offset - 1\n",
    "                named_entities.append(Entity(ent_type, start_offset, end_offset))\n",
    "                start_offset = None\n",
    "                end_offset = None\n",
    "                ent_type = None\n",
    "\n",
    "        elif ent_type is None:\n",
    "            ent_type = token_tag[2:]\n",
    "            start_offset = offset\n",
    "\n",
    "        elif ent_type != token_tag[2:] or (ent_type == token_tag[2:] and token_tag[:1] == 'B'):\n",
    "\n",
    "            end_offset = offset - 1\n",
    "            named_entities.append(Entity(ent_type, start_offset, end_offset))\n",
    "\n",
    "            # start of a new entity\n",
    "            ent_type = token_tag[2:]\n",
    "            start_offset = offset\n",
    "            end_offset = None\n",
    "\n",
    "    # catches an entity that goes up until the last token\n",
    "    if ent_type and start_offset and end_offset is None:\n",
    "        named_entities.append(Entity(ent_type, start_offset, len(tokens)-1))\n",
    "\n",
    "    return named_entities\n",
    "\n",
    "def compute_metrics(true_named_entities, pred_named_entities): # Helper Function for score calculation\n",
    "    eval_metrics = {'correct': 0, 'partial': 0, 'missed': 0, 'spurius': 0}\n",
    "    target_tags_no_schema = ['indications']\n",
    "\n",
    "    # overall results\n",
    "    evaluation = {'partial': deepcopy(eval_metrics)}\n",
    "\n",
    "\n",
    "    true_which_overlapped_with_pred = []  # keep track of entities that overlapped\n",
    "\n",
    "    # go through each predicted named-entity\n",
    "    for pred in pred_named_entities:\n",
    "        found_overlap = False\n",
    "\n",
    "        # check if there's an exact match, i.e.: boundary and entity type match\n",
    "        if pred in true_named_entities:\n",
    "            true_which_overlapped_with_pred.append(pred)\n",
    "            evaluation['partial']['correct'] += 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            # check for overlaps with any of the true entities\n",
    "            for true in true_named_entities:\n",
    "\n",
    "                \n",
    "                # 2. check for an overlap i.e. not exact boundary match, with true entities\n",
    "                if pred.start_offset <= true.end_offset and true.start_offset <= pred.end_offset:\n",
    "\n",
    "                    true_which_overlapped_with_pred.append(true)\n",
    "\n",
    "                    evaluation['partial']['partial'] += 1\n",
    "\n",
    "                    found_overlap = True\n",
    "                    break\n",
    "\n",
    "            # count spurius (i.e., False Positive) entities\n",
    "            if not found_overlap:\n",
    "                # overall results\n",
    "                evaluation['partial']['spurius'] += 1\n",
    "\n",
    "    # count missed entities (i.e. False Negative)\n",
    "    for true in true_named_entities:\n",
    "        if true in true_which_overlapped_with_pred:\n",
    "            continue\n",
    "        else:\n",
    "            # overall results\n",
    "            evaluation['partial']['missed'] += 1\n",
    "\n",
    "    # Compute 'possible', 'actual'\n",
    "    for eval_type in ['partial']:\n",
    "\n",
    "        correct = evaluation[eval_type]['correct']\n",
    "        partial = evaluation[eval_type]['partial']\n",
    "        missed = evaluation[eval_type]['missed']\n",
    "        spurius = evaluation[eval_type]['spurius']\n",
    "\n",
    "        # possible: nr. annotations in the gold-standard which contribute to the final score\n",
    "        evaluation[eval_type]['possible'] = correct + partial + missed\n",
    "\n",
    "        # actual: number of annotations produced by the NER system\n",
    "        evaluation[eval_type]['actual'] = correct + partial + spurius\n",
    "\n",
    "        actual = evaluation[eval_type]['actual']\n",
    "        possible = evaluation[eval_type]['possible']\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "def list_converter(df): # Helper Function for score calculation\n",
    "    keys, values = df.sort_values('Sent_ID_x').values.T\n",
    "    ukeys, index = np.unique(keys,True)\n",
    "    lists = [list(array) for array in np.split(values,index[1:])]\n",
    "    return lists\n",
    "\n",
    "# ideal and pred respectively represent dataframes containing actual labels and predictions for the set of sentences in the test data. \n",
    "# It has the same format as the sample submission (id, Sent_ID, tag)\n",
    "\n",
    "def calculate_score(ideal, pred): # Calculates the final F1 Score\n",
    "\n",
    "    merged = ideal.merge(pred, on = \"id\", how=\"inner\").drop(['Sent_ID_y'],axis = 1)\n",
    "    \n",
    "    \n",
    "    # The scores are calculated sentence wise and then aggregated to calculate the overall score, for this\n",
    "    # List converter function groups the labels by sentence to generate a list of lists with each inner list representing a sentence in sequence\n",
    "    ideal_ = list_converter(merged.drop(['id','tag_y'],axis = 1))\n",
    "    pred_ = list_converter(merged.drop(['id','tag_x'],axis = 1))\n",
    "\n",
    "    metrics_results = {'correct': 0, 'partial': 0,\n",
    "                   'missed': 0, 'spurius': 0, 'possible': 0, 'actual': 0}\n",
    "\n",
    "    results = {'partial': deepcopy(metrics_results)}\n",
    "\n",
    "\n",
    "    for true_ents, pred_ents in zip(ideal_, pred_):    \n",
    "    # compute results for one sentence\n",
    "        tmp_results = compute_metrics(collect_named_entities(true_ents),collect_named_entities(pred_ents))\n",
    "    \n",
    "    # aggregate overall results\n",
    "        for eval_schema in results.keys():\n",
    "            for metric in metrics_results.keys():\n",
    "                results[eval_schema][metric] += tmp_results[eval_schema][metric]\n",
    "    correct = results['partial']['correct']\n",
    "    partial = results['partial']['partial']\n",
    "    missed = results['partial']['missed']\n",
    "    spurius = results['partial']['spurius']\n",
    "    actual = results['partial']['actual']\n",
    "    possible = results['partial']['possible']\n",
    "\n",
    "\n",
    "    precision = (correct + 0.5 * partial) / actual if actual > 0 else 0\n",
    "    recall = (correct + 0.5 * partial) / possible if possible > 0 else 0\n",
    "\n",
    "\n",
    "    score = (2 * precision * recall)/(precision + recall) if (precision + recall) >0 else 0\n",
    "    \n",
    "    # final score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data and analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag\n",
       "0   1       1        1        Obesity   O\n",
       "1   2       1        1             in   O\n",
       "2   3       1        1           Low-   O\n",
       "3   4       1        1            and   O\n",
       "4   5       1        1  Middle-Income   O"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543833, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Doc_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191282"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sent_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4543833"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have total 30000 documents and 191282 sentances in total.\n",
    "\n",
    "We have total 4543833 unique id, which means each record is assigned unique id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sci-spacy demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" RECORD #14806 421857826 | BHO | 95616398 | | 9654751 | 8/0/2006 12:00:00 AM | HAND CELLULITIS | Signed | DIS | Admission Date: 7/22/2006 Report Status: Signed Discharge Date: 5/24/2006\n",
    "ATTENDING: DEMONT , CRAIG JEWELL MD\n",
    "PRINCIPAL DIAGNOSIS: Cellulitis.\n",
    "LIST OF PROBLEMS/DIAGNOSES:\n",
    "1. Inflammatory breast cancer.\n",
    "2. Type II diabetes.\n",
    "3. Hypertension.\n",
    "4. Hypercholesterolemia.\n",
    "5. CHF with preserved systolic function.\n",
    "6. Obstructive sleep apnea.\n",
    "7. Asthma.\n",
    "8. Spinal stenosis with herniated discs.\n",
    "BRIEF HISTORY OF PRESENT ILLNESS: Ms. Schwarzer is a 72-year-old female with newly diagnosed ductal carcinoma and inflammatory breast cancer of the left breast with a mass in the lung that is suggestive of likely stage IV disease who has also multiple other medical problem including diabetes , who presents with a two-day history of right and left finger warmth , tenderness and swelling. The patient is undergoing chemotherapy with Adriamycin and cytoxan and is status post cycle 2 on 10/28/06 and began to feel like she was recovering from her chemotherapy approximately three days prior to admission. A spinal MRI obtained on Tuesday to evaluate her spinal stenosis was uneventful but later on that day the patient developed redness on the dorsum of her right hand in the area in which her IV was placed per the MRI. The following morning the patient had a pustular lesion on the fourth digit of her right hand distal to the dorsal redness and went to EH Urgent Care where she received one dose of ceftriaxone and was given a p.o. script for Augmentin. She was sent home but at home she developed expulsive diarrhea and vomiting on that evening , was not able to tolerate her oral antibiotics. The next day she noticed a similar lesion on the fourth digit of her left hand looking much like that on the right hand. She returned to the TMHMC urgent care for one more dose of ceftriaxone and was then admitted to the hospital for IV antibiotics. The patient denies any cat bites , travel , soil or water contract. She has no bruises , scrapes or previous lesions.\n",
    "PAST MEDICAL HISTORY: As detailed above.\n",
    "MEDICINES:\n",
    "1. Lantus 40 units nightly.\n",
    "2. Aspirin 81 mg daily.\n",
    "3. Lipitor 40 mg daily.\n",
    "4. Zestril 2.5 mg daily.\n",
    "5. Cardizem ER 240 mg daily.\n",
    "6. Lasix 20 mg daily.\n",
    "7. Procrit 40000 units weekly.\n",
    "8. Pamidronate.\n",
    "9. Dexamethasone with chemotherapy.\n",
    "10. AC chemo.\n",
    "11. Neulasta.\n",
    "12. Ativan p.r.n.\n",
    "13. Multivitamin.\n",
    "14. Iron sulfate.\n",
    "15. Isosorbide dinitrate 10 mg t.i.d.\n",
    "11. Allegra 60 , 000 mg b.i.d.\n",
    "ALLERGIES:\n",
    "1. Percodan.\n",
    "2. Halothane causing fevers.\n",
    "3. Atenolol causing sweating.\n",
    "4. Sulfa causes a rash.\n",
    "SOCIAL HISTORY: The patient lives alone in Te She has a very sad social history in which her husband is a TX war veteran and came back to the Ra and was service connected with the pofield medical center of psychiatric disturbances following his tour of duty. She has had three sons , two twins who died earlier in life of some unspecified heart illness and a third son who died at the age of 21 after a long hospital stay with clear cell sarcoma of bone. She lives alone\n",
    "in a second floor walkup in Du near Inslareca Cou Pla She\n",
    "has a distant history of tobacco 50 years ago. She rarely drinks\n",
    "alcohol. Her friend and healthcare proxy is Ezekiel Stoviak , and\n",
    "the phone # 286-432-6775.\n",
    "FAMILY HISTORY: There is no history of breast cancer. Mother\n",
    "had colon cancer. Three aunts and maternal grandmother also had\n",
    "colon cancer. Her son had a clear cell sarcoma of bone.\n",
    "REVIEW OF SYSTEMS: Positive for nausea , vomiting , diarrhea ,\n",
    "lightheadedness and dizziness associated with her chemo but she\n",
    "denies fevers , chills , sweats in the past 72 to 96 hours prior to\n",
    "admission. She did have chest pain on 1/22/06 two days after\n",
    "her chemo but none since and in the time leading up to her\n",
    "hospitalization.\n",
    "ADMISISON PHYSICAL EXAM: Temperature was 98.9 , pulse 98 , blood\n",
    "pressure 132/55 , respiratory rate 16 , 95% on room air. The\n",
    "patient's physical exam was significant for alopecia and obesity.\n",
    "She was in no acute distress , alert and oriented. Her pupils\n",
    "were equal , round and reactive. Conjunctivae were pink. She was\n",
    "anicteric and her oropharynx was clear. JVP was hard to assess\n",
    "due to neck fullness and she wears hearing aids. The lungs were\n",
    "clear to auscultation except for decreased breath sounds with\n",
    "crackles at the left base. Cardiovascular exam was regular rate\n",
    "and rhythm with a normal S1 , S2 and no murmur , rubs or gallops.\n",
    "Abdomen was soft and benign. Extremities had trace to 1+ edema.\n",
    "The patient had an approximately 4 x 2 cm area of redness but no\n",
    "swelling , positive warmth and positive tenderness on the dorsal\n",
    "surface of her right hand. She had a pustular lesion on her left\n",
    "fourth digit and right third digit that had been I&amp;D in AH\n",
    "Urgent Care.\n",
    "LABORATORY DATA: Labs are significant for creatinine of 1 , white\n",
    "blood cell count of 4.33 , hematocrit of 25.5 and platelets of\n",
    "108. EKG showed a normal sinus rhythm with a leftward axis and\n",
    "first degree AV block. Chest x-ray was unremarkable.\n",
    "HOSPITAL COURSE BY PROBLEM: This is a 72-year-old woman with\n",
    "stage III or stage IV breast cancer who now presents with\n",
    "paronychia and possible cellulitis of her right and left hands.\n",
    "Infectious Disease: The patient was initially started on IV\n",
    "vancomycin given the proximity of her recent chemotherapy. Her\n",
    "finger lesions and dorsal right hand lesions began to heal within\n",
    "two days of her admission. She underwent incision and drainage\n",
    "of her left hand's pustular lesion with improved speed of healing\n",
    "and decreased pain. After 48 hours in the hospital the patient's\n",
    "vancomycin was switched to Keflex at which time the patient\n",
    "developed a area of redness on her left forearm that measured\n",
    "approximately 6 cm x 4 cm in area. The lesion was notable for an\n",
    "erythematous base with punctuate red lesions that did not appear\n",
    "to be blanching. At the same time , she developed a very similar\n",
    "lesion on her right index finger between her MCP and PIP. The\n",
    "patient was switched back to IV vancomycin and the Infectious\n",
    "Disease consultants were called to assist with the management of\n",
    "the patient's evolving lesions. A TTE was obtained that showed no\n",
    "vegetations and serial blood cultures showed no bacteremia. The\n",
    "Infectious Disease consultants suggested that the patient had\n",
    "paronychia in her digits with transfer of bacterial infestation\n",
    "due to skin breakdown in the area around her nails on her hands.\n",
    "The concern for septic emboli for which the patient was initially\n",
    "treated became less likely in the setting of the new lesions that\n",
    "were not in distribution that has been consistent with septic\n",
    "emboli. 48 hours later the patient was again switched from\n",
    "vancomycin to Keflex and within 12 hours developed new\n",
    "maculopapular rash on her right neck and furuncles on her left\n",
    "and right outer labia that were exquisitely painful. The patient\n",
    "was given one more dose of IV vancomycin and then resumed on\n",
    "Keflex. Dermatologists were consulted to help determine whether\n",
    "the patient was suffering from shingles and they deemed that she\n",
    "was not and that her new rash was likely eczematous in nature and\n",
    "topical steroid creams were prescribed. The new rash on the\n",
    "right neck quickly resolved and the furuncles on her labia were\n",
    "symptomatically managed with sitz bath three times daily in\n",
    "addition to her oral cephalosporin antibiotic.\n",
    "Throughout the course of evolving dermatologic findings that the\n",
    "patient experienced and the pain associated with them the patient\n",
    "had continued to have absolutely no systemic complications\n",
    "associated with these lesions. In particular , she did not have\n",
    "fever at all during the course of her hospitalization , she did\n",
    "not have chills or sweats , she developed no new heart murmurs ,\n",
    "and her blood cultures remained negative throughout the course.\n",
    "The patient was started on IV acyclovir when her new rash\n",
    "developed and on the day of discharge was switched over to\n",
    "Valtrex 1000 mg t.i.d. for management of presumed HSV infection\n",
    "though cultures remained pending at the time of discharge. The\n",
    "patient will be discharged on Keflex and Valtrex to complete a\n",
    "course of ten days on each.\n",
    "Endocrine: The patient has a history of type II diabetes , was\n",
    "placed on a weight based insulin regimen with good effect during\n",
    "the course of her hospitalization. On discharge , she will resume\n",
    "her Lantus 40 units nightly.\n",
    "Cardiovascular: The patient has a history of diastolic\n",
    "dysfunction with a clean cath in 2005. Her aspirin , statin ,\n",
    "Zestril , Cardizem , Lasix and nitrates were continued during the\n",
    "course of her hospitalization in the same way that she takes them\n",
    "at home with very well controlled blood pressures and no issues\n",
    "with her rhythm.\n",
    "The patient has a history of obstructive sleep apnea but does not\n",
    "use CPAP and do not have any difficulties with her oxygenation\n",
    "even while sleeping.\n",
    "Heme: The patient was initially anemic and thrombocytopenic on\n",
    "admission. She received one unit of packed red blood cells and\n",
    "her hematocrit remained stable through the duration of her\n",
    "hospitalization.\n",
    "Oncology: The patient has ductal carcinoma and inflammatory\n",
    "breast cancer that is likely stage IV and she is status post\n",
    "cycle 2 of 16 of neoadjuvant chemotherapy with Adriamycin and\n",
    "cytoxan with a plan for surgical removal after her\n",
    "chemotherapy.\n",
    "DISPOSITION: The patient will be discharged to home with VNA\n",
    "services and physical therapy at home.\n",
    "DISCHARGE MEDICATIONS: Tylenol 650 mg p.o. q.4 h. p.r.n.\n",
    "headache , aspirin 81 mg daily , Lipitor 40 mg daily , bacitracin\n",
    "topical to rash twice daily , Keflex 500 mg p.o. q.i.d. x5 days\n",
    "starting on 0/10/06 to be completed on 5/24/06 , chlorhexidine\n",
    "three packets daily washing area of rash , darbepoetin 100 mcg\n",
    "subcutaneously weekly , diltiazem ER 240 mg daily , Colace 100 mg\n",
    "twice daily , ferrous sulfate 300 mg daily , Allegra 60 mg twice\n",
    "daily , Lasix 20 mg daily , hydrocortisone 2.5% cream topically\n",
    "twice daily to rash , Dilaudid 2 to 4 mg p.o. q.4 h. p.r.n. pain ,\n",
    "Lantus 40 units subcutaneously every evening , isosorbide\n",
    "dinitrate 10 mg three times daily , Zestril 2.5 mg daily , Ativan\n",
    "0.5 mg twice daily p.r.n. nausea , insomnia and anxiety , ocean\n",
    "nasal spray two sprays nasally four times a day , multivitamin one\n",
    "tab daily , Valtrex 1000 mg q.8 h. x21 doses , triamcinolone cream\n",
    "topically once daily.\n",
    "PHYSICIAN FOLLOWUP PLANS: The patient will call Dr. Abed 's\n",
    "clinic to make an appointment to follow up with her.\n",
    "The patient is full code.\n",
    "eScription document: 3-1182895 CSSten Tel\n",
    "Dictated By: CHINN , GARFIELD\n",
    "Attending: MASUNAGA , BARNEY TRACY\n",
    "Dictation ID 7197618\n",
    "D: 0/10/06\n",
    "T: 0/10/06\n",
    "[report_end]\n",
    "\"\"\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5/24/2006\\n', 'CHEMICAL'),\n",
       " ('DEMONT', 'CHEMICAL'),\n",
       " ('Cellulitis', 'DISEASE'),\n",
       " ('breast cancer', 'DISEASE'),\n",
       " ('Hypertension', 'DISEASE'),\n",
       " ('Hypercholesterolemia', 'DISEASE'),\n",
       " ('CHF', 'DISEASE'),\n",
       " ('ductal carcinoma', 'DISEASE'),\n",
       " ('breast cancer', 'DISEASE'),\n",
       " ('diabetes', 'DISEASE'),\n",
       " ('tenderness', 'DISEASE'),\n",
       " ('swelling', 'DISEASE'),\n",
       " ('Adriamycin', 'CHEMICAL'),\n",
       " ('cytoxan', 'CHEMICAL'),\n",
       " ('pustular lesion', 'DISEASE'),\n",
       " ('ceftriaxone', 'CHEMICAL'),\n",
       " ('Augmentin', 'CHEMICAL'),\n",
       " ('diarrhea', 'DISEASE'),\n",
       " ('vomiting', 'DISEASE'),\n",
       " ('TMHMC', 'CHEMICAL'),\n",
       " ('ceftriaxone', 'CHEMICAL'),\n",
       " ('bites', 'DISEASE'),\n",
       " ('bruises', 'DISEASE'),\n",
       " ('MEDICINES', 'DISEASE'),\n",
       " ('Aspirin', 'CHEMICAL'),\n",
       " ('Lipitor', 'CHEMICAL'),\n",
       " ('Lasix', 'CHEMICAL'),\n",
       " ('Pamidronate', 'CHEMICAL'),\n",
       " ('Dexamethasone', 'CHEMICAL'),\n",
       " ('chemo', 'CHEMICAL'),\n",
       " ('Iron sulfate', 'CHEMICAL'),\n",
       " ('Isosorbide dinitrate', 'CHEMICAL'),\n",
       " ('ALLERGIES', 'CHEMICAL'),\n",
       " ('Halothane', 'CHEMICAL'),\n",
       " ('fevers', 'DISEASE'),\n",
       " ('Atenolol', 'CHEMICAL'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('Te', 'CHEMICAL'),\n",
       " ('Ra', 'CHEMICAL'),\n",
       " ('psychiatric', 'DISEASE'),\n",
       " ('heart illness', 'DISEASE'),\n",
       " ('clear cell sarcoma', 'DISEASE'),\n",
       " ('Du near', 'CHEMICAL'),\n",
       " ('Inslareca', 'CHEMICAL'),\n",
       " ('alcohol', 'CHEMICAL'),\n",
       " ('breast cancer', 'DISEASE'),\n",
       " ('colon cancer', 'DISEASE'),\n",
       " ('colon cancer', 'DISEASE'),\n",
       " ('nausea', 'DISEASE'),\n",
       " ('vomiting', 'DISEASE'),\n",
       " ('diarrhea', 'DISEASE'),\n",
       " ('dizziness', 'DISEASE'),\n",
       " ('chemo', 'CHEMICAL'),\n",
       " ('fevers', 'DISEASE'),\n",
       " ('chills', 'DISEASE'),\n",
       " ('sweats', 'DISEASE'),\n",
       " ('chest pain', 'DISEASE'),\n",
       " ('chemo', 'CHEMICAL'),\n",
       " ('alopecia', 'DISEASE'),\n",
       " ('obesity', 'DISEASE'),\n",
       " ('acute distress', 'DISEASE'),\n",
       " ('neck fullness', 'DISEASE'),\n",
       " ('decreased breath sounds', 'DISEASE'),\n",
       " ('edema', 'DISEASE'),\n",
       " ('swelling', 'DISEASE'),\n",
       " ('tenderness', 'DISEASE'),\n",
       " ('pustular lesion', 'DISEASE'),\n",
       " ('creatinine', 'CHEMICAL'),\n",
       " ('AV block', 'DISEASE'),\n",
       " ('breast cancer', 'DISEASE'),\n",
       " ('paronychia', 'DISEASE'),\n",
       " ('cellulitis', 'DISEASE'),\n",
       " ('Infectious Disease', 'DISEASE'),\n",
       " ('vancomycin', 'CHEMICAL'),\n",
       " ('decreased pain', 'DISEASE'),\n",
       " ('vancomycin', 'CHEMICAL'),\n",
       " ('blanching', 'DISEASE'),\n",
       " ('vancomycin', 'CHEMICAL'),\n",
       " ('vegetations', 'DISEASE'),\n",
       " ('bacteremia', 'DISEASE'),\n",
       " ('paronychia', 'DISEASE'),\n",
       " ('bacterial infestation', 'DISEASE'),\n",
       " ('septic emboli', 'DISEASE'),\n",
       " ('septic', 'DISEASE'),\n",
       " ('emboli', 'DISEASE'),\n",
       " ('vancomycin', 'CHEMICAL'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('furuncles', 'DISEASE'),\n",
       " ('vancomycin', 'CHEMICAL'),\n",
       " ('shingles', 'DISEASE'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('eczematous', 'DISEASE'),\n",
       " ('steroid', 'CHEMICAL'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('furuncles', 'DISEASE'),\n",
       " ('cephalosporin', 'CHEMICAL'),\n",
       " ('pain', 'DISEASE'),\n",
       " ('fever', 'DISEASE'),\n",
       " ('chills', 'DISEASE'),\n",
       " ('sweats', 'DISEASE'),\n",
       " ('heart murmurs', 'DISEASE'),\n",
       " ('acyclovir', 'CHEMICAL'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('HSV infection', 'DISEASE'),\n",
       " ('type II diabetes', 'DISEASE'),\n",
       " ('Lantus', 'CHEMICAL'),\n",
       " ('aspirin', 'CHEMICAL'),\n",
       " ('statin', 'CHEMICAL'),\n",
       " ('Zestril', 'CHEMICAL'),\n",
       " ('Lasix', 'CHEMICAL'),\n",
       " ('nitrates', 'CHEMICAL'),\n",
       " ('obstructive sleep apnea', 'DISEASE'),\n",
       " ('thrombocytopenic', 'DISEASE'),\n",
       " ('ductal carcinoma', 'DISEASE'),\n",
       " ('breast cancer', 'DISEASE'),\n",
       " ('Adriamycin', 'CHEMICAL'),\n",
       " ('cytoxan', 'CHEMICAL'),\n",
       " ('DISCHARGE', 'CHEMICAL'),\n",
       " ('Tylenol', 'CHEMICAL'),\n",
       " ('headache', 'DISEASE'),\n",
       " ('aspirin', 'CHEMICAL'),\n",
       " ('Lipitor', 'CHEMICAL'),\n",
       " ('bacitracin', 'CHEMICAL'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('0/10/06', 'CHEMICAL'),\n",
       " ('chlorhexidine', 'CHEMICAL'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('diltiazem', 'CHEMICAL'),\n",
       " ('ferrous sulfate', 'CHEMICAL'),\n",
       " ('Lasix', 'CHEMICAL'),\n",
       " ('hydrocortisone', 'CHEMICAL'),\n",
       " ('rash', 'DISEASE'),\n",
       " ('pain', 'DISEASE'),\n",
       " ('Lantus', 'CHEMICAL'),\n",
       " ('isosorbide', 'CHEMICAL'),\n",
       " ('dinitrate', 'CHEMICAL'),\n",
       " ('nausea', 'DISEASE'),\n",
       " ('insomnia', 'DISEASE'),\n",
       " ('anxiety', 'DISEASE'),\n",
       " ('multivitamin', 'CHEMICAL'),\n",
       " ('triamcinolone', 'CHEMICAL'),\n",
       " ('CSSten', 'CHEMICAL'),\n",
       " ('CHINN', 'CHEMICAL')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(e.text, e.label_) for e in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(X, X.ent_iob_, X.ent_type_) for X in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spacy NER prediction dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create train and validation set.\n",
    "\n",
    "We are doing this based on if a doc has any entity in it or not.\n",
    "\n",
    "We will create stratified train and test split based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_ent = train_df.groupby('Doc_ID')['tag'].apply(lambda x: 'B-indications' in x.values).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Doc_ID    tag\n",
       "0       1   True\n",
       "1       2   True\n",
       "2       3   True\n",
       "3       4  False\n",
       "4       5  False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_ent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train Doc ids and validation Doc ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_doc_ids, tst_doc_ids = train_test_split(has_ent['Doc_ID'].values, test_size = 0.33, stratify=has_ent['tag'].values, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100  training documents.\n"
     ]
    }
   ],
   "source": [
    "print(len(trn_doc_ids), \" training documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900  test documents.\n"
     ]
    }
   ],
   "source": [
    "print(len(tst_doc_ids), \" test documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = train_df[train_df['Doc_ID'].isin(tst_doc_ids)].reset_index(drop=True)\n",
    "train_df = train_df[train_df['Doc_ID'].isin(trn_doc_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train our model on document level and also predict on document level, that's why we need to group data by Doc_ID.\n",
    "\n",
    "The reason behid this is that in training out model can use context words and learn better.\n",
    "\n",
    "Same goes for prediction. If we just single word for prediction, then model doesn't know its context words, and model can't predict better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main problem we face in using using spacy for prediction is that it takes whole document, do tokenization on its own and give us IOB (inside, outside, begining) prediction on tokens it has generated. Here we might face mismatch between tokens of spacy and our own, we need IOB predictions on our own tokens.\n",
    "\n",
    "That's why we have created a function which gives use prediction based on word location in document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating test data for prediction\n",
    "def gb_ops_test(df):\n",
    "    ids = df['id'].tolist()\n",
    "    st_inds = []\n",
    "    doc = \"\"\n",
    "    ls_ind = 0\n",
    "    for w in df['Word']:\n",
    "        st_inds.append(ls_ind)\n",
    "        w_len = len(str(w))\n",
    "        ls_ind = ls_ind + w_len + 1\n",
    "        doc = doc + str(w) + \" \"\n",
    "    return pd.Series(dict(ids = ids, st_inds = st_inds, doc = doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_df.groupby('Doc_ID').apply(gb_ops_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>st_inds</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[212, 213]</td>\n",
       "      <td>[0, 14]</td>\n",
       "      <td>MICROCEPHALIA VERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[214, 215, 216, 217, 218, 219, 220, 221, 222, ...</td>\n",
       "      <td>[0, 10, 26, 29, 35, 43, 52, 60, 63, 70, 75, 89...</td>\n",
       "      <td>Excellent reproducibility of laser speckle con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[519, 520, 521, 522, 523, 524, 525, 526, 527, ...</td>\n",
       "      <td>[0, 9, 19, 26, 29, 44, 47, 51, 63, 68, 74]</td>\n",
       "      <td>Positive inotropic action of cholinesterase on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[830, 831, 832, 833, 834, 835, 836, 837, 838, ...</td>\n",
       "      <td>[0, 15, 20, 29, 37, 39, 44, 46, 48, 51, 60, 65...</td>\n",
       "      <td>Self-assembled drug delivery systems . Part 8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[1066, 1067, 1068, 1069, 1070, 1071, 1072, 107...</td>\n",
       "      <td>[0, 12, 16, 23, 34, 37, 44, 54, 57, 77, 87, 92...</td>\n",
       "      <td>Hyperphagia and leptin resistance in tissue in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ids  \\\n",
       "Doc_ID                                                      \n",
       "2                                              [212, 213]   \n",
       "3       [214, 215, 216, 217, 218, 219, 220, 221, 222, ...   \n",
       "4       [519, 520, 521, 522, 523, 524, 525, 526, 527, ...   \n",
       "6       [830, 831, 832, 833, 834, 835, 836, 837, 838, ...   \n",
       "7       [1066, 1067, 1068, 1069, 1070, 1071, 1072, 107...   \n",
       "\n",
       "                                                  st_inds  \\\n",
       "Doc_ID                                                      \n",
       "2                                                 [0, 14]   \n",
       "3       [0, 10, 26, 29, 35, 43, 52, 60, 63, 70, 75, 89...   \n",
       "4              [0, 9, 19, 26, 29, 44, 47, 51, 63, 68, 74]   \n",
       "6       [0, 15, 20, 29, 37, 39, 44, 46, 48, 51, 60, 65...   \n",
       "7       [0, 12, 16, 23, 34, 37, 44, 54, 57, 77, 87, 92...   \n",
       "\n",
       "                                                      doc  \n",
       "Doc_ID                                                     \n",
       "2                                     MICROCEPHALIA VERA   \n",
       "3       Excellent reproducibility of laser speckle con...  \n",
       "4       Positive inotropic action of cholinesterase on...  \n",
       "6       Self-assembled drug delivery systems . Part 8 ...  \n",
       "7       Hyperphagia and leptin resistance in tissue in...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, ids contains word ids in doc, st_inds has starting index of all words which are in doc. and doc is text document.\n",
    "\n",
    "ids and st_inds has samesize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a benchmark model using pre trained Sci Spacy 'en_ner_bc5cdr_md' model\n",
    "\n",
    "Which is a NER for DISEASE and CHEMICHAL entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for prediction on document and returns 'B' and 'I' word ids in our dataset\n",
    "\n",
    "def get_tag(ids, st_inds, doc, nlp_obj):\n",
    "    ids = pd.Series(ids)\n",
    "    st_inds = pd.Series(st_inds)\n",
    "\n",
    "    doc = nlp_obj(str(doc))\n",
    "    out = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "\n",
    "    ans = {'B': [], 'I': []}\n",
    "\n",
    "    for o in out:\n",
    "        if o[3] == 'DISEASE':\n",
    "            inss = st_inds[(st_inds >= o[1]) & (st_inds <= o[2])].index.tolist()\n",
    "            if (st_inds == o[1]).sum() == 0:\n",
    "                inss = [(st_inds[st_inds > o[1]].index[0] - 1)] + inss\n",
    "            w_ids = ids.iloc[inss].tolist()\n",
    "            ans['B'].append(w_ids[0])\n",
    "            ans['I'].extend(w_ids[1:])\n",
    "    return ans\n",
    "\n",
    "def get_B_I_ids(temp_data):\n",
    "    B_pred_ids = []\n",
    "    I_pred_ids = []\n",
    "    for d in temp_data:\n",
    "        B_pred_ids.extend(d['B'])\n",
    "        I_pred_ids.extend(d['I'])\n",
    "        \n",
    "    return B_pred_ids, I_pred_ids\n",
    "\n",
    "def make_prediction(test_df, B_pred_ids, I_pred_ids):\n",
    "    ans = test_df[['id', 'Sent_ID']].copy()\n",
    "    ans['tag'] = 'O'\n",
    "    ans.loc[ans['id'].isin(B_pred_ids), 'tag'] = 'B-indications'\n",
    "    ans.loc[ans['id'].isin(I_pred_ids), 'tag'] = 'I-indications'\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.402213720480601  minutes\n"
     ]
    }
   ],
   "source": [
    "# spacy NLP object\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "# function to put nlp object in get_tag function\n",
    "def mp_get_tag(ids, st_inds, doc):\n",
    "    return get_tag(ids, st_inds, doc, nlp)\n",
    "\n",
    "## Multiprocess code\n",
    "t1 = time.time()\n",
    "p = Pool(N_CORES)\n",
    "temp_data = list(p.starmap(mp_get_tag, zip(list(test_data['ids'].values), list(test_data['st_inds'].values), list(test_data['doc'].values))))\n",
    "p.close()\n",
    "p.join()\n",
    "p.terminate()\n",
    "print((time.time() - t1)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_pred_ids, I_pred_ids = get_B_I_ids(temp_data)\n",
    "test_pred_bm = make_prediction(test_df, B_pred_ids, I_pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>10</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>10</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>215</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>216</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Sent_ID tag\n",
       "0  212       10   O\n",
       "1  213       10   O\n",
       "2  214       11   O\n",
       "3  215       11   O\n",
       "4  216       11   O"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_bm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5200572193815438"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score(test_df[['id', 'Sent_ID', 'tag']], test_pred_bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 0.489518489355064 score on validation set using sci spacy pre trained model.\n",
    "\n",
    "On leader board highest score is 0.82.\n",
    "\n",
    "We can Update (further train) this sci spacy model on our train dataset to increase score upto 0.80 and even higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spacy train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trn_data(df):\n",
    "    ent_pres = False\n",
    "    doc = \"\"\n",
    "    ents = []\n",
    "    new_ind = 0\n",
    "    \n",
    "    for i, r in df.iterrows():\n",
    "        w_len = len(str(r['Word']))\n",
    "        doc = doc + str(r['Word']) + \" \"\n",
    "        \n",
    "        if r['tag'] == 'O':\n",
    "            new_ind = new_ind + w_len + 1\n",
    "            \n",
    "        if r['tag'] == 'B-indications':\n",
    "            st = new_ind\n",
    "            en = st + w_len\n",
    "            ents.append((st, en, 'DISEASE'))\n",
    "            new_ind = en + 1\n",
    "            \n",
    "        if r['tag'] == 'I-indications':\n",
    "            en = new_ind + w_len\n",
    "            st = ents[-1][0]\n",
    "            ents = ents[0:-1]\n",
    "            ents.append((st, en, 'DISEASE'))\n",
    "            new_ind = en + 1\n",
    "    \n",
    "    if ents:\n",
    "        ent_pres = True\n",
    "    \n",
    "    out = (doc, {\"entities\": ents})\n",
    "    return pd.Series(dict(trn_data = out, ent_pres = ent_pres))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.groupby('Sent_ID').apply(create_trn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trn_data</th>\n",
       "      <th>ent_pres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sent_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(Obesity in Low- and Middle-Income Countries :...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(We have reviewed the distinctive features of ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(Obesity is rising in every region of the worl...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(In LMICs , overweight is higher in women comp...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(Overweight occurs alongside persistent burden...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  trn_data  ent_pres\n",
       "Sent_ID                                                             \n",
       "1        (Obesity in Low- and Middle-Income Countries :...     False\n",
       "2        (We have reviewed the distinctive features of ...     False\n",
       "3        (Obesity is rising in every region of the worl...     False\n",
       "4        (In LMICs , overweight is higher in women comp...     False\n",
       "5        (Overweight occurs alongside persistent burden...     False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Obesity in Low- and Middle-Income Countries : Burden , Drivers , and Emerging Challenges . ',\n",
       " {'entities': []})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0]['trn_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train sci spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trn_model(model= None, output_dir=None, n_iter=10):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # reset and initialize the weights randomly – but only if we're\n",
    "        # training a new model\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in tqdm(batches):\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.3,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(\"Losses\", losses)\n",
    "    \n",
    "            # save model to output directory\n",
    "            if output_dir is not None:\n",
    "                output_dir = Path(output_dir)\n",
    "                if not output_dir.exists():\n",
    "                    output_dir.mkdir()\n",
    "                nlp.to_disk(output_dir)\n",
    "                print(\"Saved model to\", output_dir)\n",
    "\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = train_data['trn_data'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"en_ner_bc5cdr_md\"\n",
    "OUT_DIR = \"./model_final/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_ner_bc5cdr_md'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ad16cd707a43a5bfdb7ef6fd79753d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 129.74318817221916}\n",
      "Saved model to model_final\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c0b947c99b4366a6bd8e1a8e46ea5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 86.04977100593487}\n",
      "Saved model to model_final\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b090e4da5e94017b3be145b8929e1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 74.31878978241406}\n",
      "Saved model to model_final\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca931eeb15124a95bd0018fabe668c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 61.91225983773926}\n",
      "Saved model to model_final\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc583e716d5147809d4df16bce0cc44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 57.74447276394376}\n",
      "Saved model to model_final\n"
     ]
    }
   ],
   "source": [
    "nlp1 = trn_model(MODEL, OUT_DIR, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's predict on test set using this new updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.970260135332743  minutes\n"
     ]
    }
   ],
   "source": [
    "# function to put nlp object in get_tag function\n",
    "def mp_get_tag(ids, st_inds, doc):\n",
    "    return get_tag(ids, st_inds, doc, nlp1)\n",
    "\n",
    "## Multiprocess code\n",
    "t1 = time.time()\n",
    "p = Pool(N_CORES)\n",
    "temp_data = list(p.starmap(mp_get_tag, zip(list(test_data['ids'].values), list(test_data['st_inds'].values), list(test_data['doc'].values))))\n",
    "p.close()\n",
    "p.join()\n",
    "p.terminate()\n",
    "print((time.time() - t1)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_pred_ids, I_pred_ids = get_B_I_ids(temp_data)\n",
    "test_pred_final = make_prediction(test_df, B_pred_ids, I_pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>10</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213</td>\n",
       "      <td>10</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Sent_ID tag\n",
       "0  212       10   O\n",
       "1  213       10   O\n",
       "2  214       11   O\n",
       "3  215       11   O\n",
       "4  216       11   O"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                1466397\n",
       "B-indications      16878\n",
       "I-indications      13501\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_final['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7855966520062774"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score(test_df[['id', 'Sent_ID', 'tag']], test_pred_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got a huge improvement over base pre trained model.\n",
    "\n",
    "We can train for few more epoch to increase the score.\n",
    "\n",
    "Just load this trained model and train it for few more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model score : 0.7855966520062774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
